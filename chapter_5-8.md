# 第五章 误差从哪里来
偏差 error  和方差 variance  
![](https://tva1.sinaimg.cn/large/e6c9d24ely1h37tc0kffpj20fx0d0my1.jpg)
往往越复杂的模型会带来越大的方差，但会带来更小的偏差。  
**简单模型**： 偏差大，方差小，欠拟合。
**复杂模型**： 偏差小，方差大，过拟合。

如果模型没有很好的训练训练集，就是偏差过大，也就是欠拟合。  
如果模型很好的训练训练集，即再训练集上得到很小的错误，但在测试集上得到大的错误，这意味着模型可能是方差比较大，就是过拟合。  
对于欠拟合和过拟合，是用不同的方式来处理的。
### 偏差大-欠拟合
重新设计模型，考虑更复杂的模型和更多的数据特征。
### 方差大-过拟合
更多的数据，正则化。
## 交叉验证
通过交叉验证的方式可以避免模型在训练集过拟合的情况。  
N-折交叉验证。

# 第六章 梯度下降
通过根据loss函数的结果计算每个参数的梯度，之后使用梯度下降公式来更新每个参数。重复这个过程，就是梯度下降。  
## 调整学习率
![](https://tva1.sinaimg.cn/large/e6c9d24ely1h393vpw8thj20m70mc41r.jpg)
**自适应学习率**：学习率会随着训练轮次的增多而逐渐变小。
## Adagrad 算法
![](https://tva1.sinaimg.cn/large/e6c9d24ely1h393vhf60qj20my0npwfr.jpg)
![](https://tva1.sinaimg.cn/large/e6c9d24ely1h3942dtp4ij20m601t74d.jpg)
## 随即梯度下降法
每次梯度下降只计算一个例子的loss和梯度，只使用一个就进行参数的更新。
## 特征缩放
![](https://tva1.sinaimg.cn/large/e6c9d24ely1h396ah2exdj20i50optau.jpg)
可以更有效的做梯度下降。

## 总结
学习了偏差(bias)和方差(variance)两个概念，知道了偏差、方差对模型的影响，以及对应的解决方法。同时也更加详细的学习的梯度下降法，掌握了各种梯度下降的优化方法。